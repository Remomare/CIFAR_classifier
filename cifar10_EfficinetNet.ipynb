{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "cifar10_EfficinetNet",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x91VIMoTvwVu"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X06uoyTQweqR"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqIgkSOTvwVu"
      },
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.Resize((224,224)),\n",
        "     transforms.ToTensor(), \n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 64 \n",
        "\n",
        "trainset = torchvision.datasets.CIFAR100(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR100(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x677x__GCf-T"
      },
      "source": [
        "def swich_fn(x): # Swish activation function \n",
        "    return x * torch.sigmoid(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JobAfojXC6Fj"
      },
      "source": [
        "class Conv2dSamePadding(nn.Conv2d): # 2D Convolutions like TensorFlow \n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, dilation=1, groups=1, bias=True):\n",
        "        super().__init__(in_channels, out_channels, kernel_size, stride, 0, dilation, groups, bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ih, iw = x.size()[-2:]\n",
        "        kh, kw = self.weight.size()[-2:]\n",
        "        sh, sw = self.stride\n",
        "        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n",
        "        pad_h = max((oh - 1) * self.stride[0] + (kh - 1) * self.dilation[0] + 1 - ih, 0)\n",
        "        pad_w = max((ow - 1) * self.stride[1] + (kw - 1) * self.dilation[1] + 1 - iw, 0)\n",
        "        if pad_h > 0 or pad_w > 0:\n",
        "            x = F.pad(x, [pad_w//2, pad_w - pad_w//2, pad_h//2, pad_h - pad_h//2])\n",
        "        return F.conv2d(x, self.weight, self.bias, self.stride, self.padding, self.dilation, self.groups)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaFuRLrPDOxl"
      },
      "source": [
        "def drop_connect(inputs, p, training): # Drop connect. \n",
        "    if not training: return inputs\n",
        "    batch_size = inputs.shape[0]\n",
        "    keep_prob = 1 - p\n",
        "    random_tensor = keep_prob\n",
        "    random_tensor += torch.rand([batch_size, 1, 1, 1], dtype=inputs.dtype)  # uniform [0,1)\n",
        "    binary_tensor = torch.floor(random_tensor)\n",
        "    output = inputs / keep_prob * binary_tensor\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AYQ2ifEDY45"
      },
      "source": [
        "class MBConvBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Mobile Inverted Residual Bottleneck Block\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kernel_size, stride, expand_ratio, input_filters, output_filters, se_ratio, drop_n_add):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._bn_mom = 0.1\n",
        "        self._bn_eps = 1e-03\n",
        "        self.has_se = (se_ratio is not None) and (0 < se_ratio <= 1)\n",
        "        self.expand_ratio = expand_ratio\n",
        "        self.drop_n_add = drop_n_add\n",
        "\n",
        "        # Filter Expansion phase\n",
        "        inp = input_filters  # number of input channels\n",
        "        oup = input_filters * expand_ratio  # number of output channels\n",
        "        if expand_ratio != 1: # add it except at first block \n",
        "            self._expand_conv = Conv2dSamePadding(in_channels=inp, out_channels=oup, kernel_size=1, bias=False)\n",
        "            self._bn0 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
        "\n",
        "        # Depthwise convolution phase\n",
        "        k = kernel_size\n",
        "        s = stride\n",
        "        self._depthwise_conv = Conv2dSamePadding(\n",
        "            in_channels=oup, out_channels=oup, groups=oup,  # groups makes it depthwise(conv filter by filter)\n",
        "            kernel_size=k, stride=s, bias=False)\n",
        "        self._bn1 = nn.BatchNorm2d(num_features=oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
        "\n",
        "        # Squeeze and Excitation layer, if desired\n",
        "        if self.has_se:\n",
        "            num_squeezed_channels = max(1,int(input_filters * se_ratio))  # input channel * 0.25 ex) block2 => 16 * 0.25 = 4\n",
        "            self._se_reduce = Conv2dSamePadding(in_channels=oup, out_channels=num_squeezed_channels, kernel_size=1)\n",
        "            self._se_expand = Conv2dSamePadding(in_channels=num_squeezed_channels, out_channels=oup, kernel_size=1)\n",
        "\n",
        "        # Output phase\n",
        "        final_oup = output_filters\n",
        "        self._project_conv = Conv2dSamePadding(in_channels=oup, out_channels=final_oup, kernel_size=1, bias=False)\n",
        "        self._bn2 = nn.BatchNorm2d(num_features=final_oup, momentum=self._bn_mom, eps=self._bn_eps)\n",
        "        \n",
        "    def forward(self, inputs, drop_connect_rate=0.2):\n",
        "\n",
        "        # Expansion and Depthwise Convolution\n",
        "        x = inputs\n",
        "        if self.expand_ratio != 1:\n",
        "            x = swich_fn(self._bn0(self._expand_conv(inputs)))\n",
        "        x = swich_fn(self._bn1(self._depthwise_conv(x)))\n",
        "\n",
        "        # Squeeze and Excitation\n",
        "        if self.has_se:\n",
        "            x_squeezed = F.adaptive_avg_pool2d(x, 1)\n",
        "            x_squeezed = self._se_expand(swich_fn(self._se_reduce(x_squeezed)))\n",
        "            x = torch.sigmoid(x_squeezed) * x\n",
        "            \n",
        "        # Output phase\n",
        "        x = self._bn2(self._project_conv(x))\n",
        "\n",
        "        # Skip connection and drop connect\n",
        "        if self.drop_n_add == True:\n",
        "            if drop_connect_rate:\n",
        "                x = drop_connect(x, p=drop_connect_rate, training=self.training)\n",
        "            x = x + inputs  # skip connection\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfoslvZkvwVw"
      },
      "source": [
        "class EfficientNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Batch norm parameters\n",
        "        bn_mom = 0.1\n",
        "        bn_eps = 1e-03\n",
        "\n",
        "        # stem\n",
        "        in_channels = 3\n",
        "        out_channels = 32\n",
        "        self._conv_stem = Conv2dSamePadding(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n",
        "        self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
        "\n",
        "        # Build blocks\n",
        "        self._blocks = nn.ModuleList([]) # list 형태로 model 구성할 때\n",
        "        # stage2 r1_k3_s11_e1_i32_o16_se0.25\n",
        "        self._blocks.append(MBConvBlock(kernel_size=3, stride=1, expand_ratio=1, input_filters=32, output_filters=16, se_ratio=0.25, drop_n_add=False))\n",
        "        # stage3 r2_k3_s22_e6_i16_o24_se0.25\n",
        "        self._blocks.append(MBConvBlock(3, 2, 6, 16, 24, 0.25, False))\n",
        "        self._blocks.append(MBConvBlock(3, 1, 6, 24, 24, 0.25, True))\n",
        "        # stage4 r2_k5_s22_e6_i24_o40_se0.25\n",
        "        self._blocks.append(MBConvBlock(5, 2, 6, 24, 40, 0.25, False))\n",
        "        self._blocks.append(MBConvBlock(5, 1, 6, 40, 40, 0.25, True))\n",
        "        # stage5 r3_k3_s22_e6_i40_o80_se0.25\n",
        "        self._blocks.append(MBConvBlock(3, 2, 6, 40, 80, 0.25, False))\n",
        "        self._blocks.append(MBConvBlock(3, 1, 6, 80, 80, 0.25, True))\n",
        "        self._blocks.append(MBConvBlock(3, 1, 6, 80, 80, 0.25, True))\n",
        "        # stage6 r3_k5_s11_e6_i80_o112_se0.25\n",
        "        self._blocks.append(MBConvBlock(5, 1, 6, 80,  112, 0.25, False))\n",
        "        self._blocks.append(MBConvBlock(5, 1, 6, 112, 112, 0.25, True))\n",
        "        self._blocks.append(MBConvBlock(5, 1, 6, 112, 112, 0.25, True))\n",
        "        # stage7 r4_k5_s22_e6_i112_o192_se0.25\n",
        "        self._blocks.append(MBConvBlock(5, 2, 6, 112, 192, 0.25, False))\n",
        "        self._blocks.append(MBConvBlock(5, 1, 6, 192, 192, 0.25, True))\n",
        "        self._blocks.append(MBConvBlock(5, 1, 6, 192, 192, 0.25, True))\n",
        "        self._blocks.append(MBConvBlock(5, 1, 6, 192, 192, 0.25, True))\n",
        "        # stage8 r1_k3_s11_e6_i192_o320_se0.25\n",
        "        self._blocks.append(MBConvBlock(3, 1, 6, 192, 320, 0.25, False))\n",
        "\n",
        "        # Head \n",
        "        in_channels = 320\n",
        "        out_channels = 1280\n",
        "        self._conv_head = Conv2dSamePadding(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "        self._bn1 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
        "\n",
        "        # Final linear layer\n",
        "        self._dropout = 0.2\n",
        "        self._num_classes = 10\n",
        "        self._fc = nn.Linear(out_channels, self._num_classes)\n",
        "\n",
        "    def extract_features(self, inputs):\n",
        "        \"\"\" Returns output of the final convolution layer \"\"\"\n",
        "\n",
        "        # Stem\n",
        "        x = swich_fn(self._bn0(self._conv_stem(inputs)))\n",
        "\n",
        "        # Blocks\n",
        "        for idx, block in enumerate(self._blocks):          \n",
        "            x = block(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        \"\"\" Calls extract_features to extract features, applies final linear layer, and returns logits. \"\"\"\n",
        "\n",
        "        # Convolution layers\n",
        "        x = self.extract_features(inputs)\n",
        "\n",
        "        # Head\n",
        "        x = swich_fn(self._bn1(self._conv_head(x)))\n",
        "        x = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
        "        if self._dropout:\n",
        "            x = F.dropout(x, p=self._dropout, training=self.training)\n",
        "        x = self._fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model = EfficientNet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZJJ4hFDvwVx"
      },
      "source": [
        "# loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# backpropagation method\n",
        "learning_rate = 1e-3\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
        "# hyper-parameters\n",
        "num_epochs = 10\n",
        "num_batches = len(trainloader)\n",
        "\n",
        "list_epoch = [] \n",
        "list_train_loss = []\n",
        "list_val_loss = []\n",
        "list_train_acc = []\n",
        "list_val_acc = []\n",
        "train_total = 0\n",
        "val_total= 0\n",
        "train_correct = 0\n",
        "val_correct = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    trn_loss = 0.0\n",
        "    train_total = 0\n",
        "    train_correct = 0\n",
        "    for i, data in enumerate(trainloader):\n",
        "        x, labels = data\n",
        "        # grad init\n",
        "        optimizer.zero_grad()\n",
        "        # forward propagation\n",
        "        model_output = model(x)\n",
        "        # calculate acc\n",
        "        _, predicted = torch.max(model_output.data, 1)\n",
        "        train_total += labels.size(0)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "        # calculate loss\n",
        "        loss = criterion(model_output, labels)\n",
        "        # back propagation \n",
        "        loss.backward()\n",
        "        # weight update\n",
        "        optimizer.step()\n",
        "        \n",
        "        # trn_loss summary\n",
        "        trn_loss += loss.item()\n",
        "        # del (memory issue)\n",
        "        del loss\n",
        "        del model_output\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(\"epoch: {}/{} | batch: {} | trn loss: {:.4f} | trn acc: {:.4f}%\".\n",
        "                  format(epoch+1, num_epochs, i+1,  trn_loss / i, 100 * train_correct / train_total)) \n",
        "        \n",
        "         \n",
        "    list_epoch.append(epoch+1)\n",
        "    list_train_loss.append(trn_loss/num_batches)\n",
        "    list_train_acc.append(100 * train_correct / train_total)\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDldvVyrvwVy"
      },
      "source": [
        "PATH = './cifar_net.pth' \n",
        "torch.save(net.state_dict(), PATH) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tmnsssavwVz"
      },
      "source": [
        "net = Net().to(device) \n",
        "net.load_state_dict(torch.load(PATH)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MCnJH8mvwV0"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad(): \n",
        "    for data in testloader: \n",
        "        images, labels = data[0].to(device), data[1].to(device) \n",
        "        outputs = net(images) \n",
        "        _, predicted = torch.max(outputs.data, 1) \n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXUahzy-vwV0"
      },
      "source": [
        "correct_pred = {classname: 0 for classname in classes} \n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "with torch.no_grad(): \n",
        "    for data in testloader: \n",
        "        images, labels = data[0].to(device), data[1].to(device)  \n",
        "        outputs = net(images) \n",
        "        _, predictions = torch.max(outputs, 1) \n",
        "        for label, prediction in zip(labels, predictions): \n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname, accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}