{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "cifar10_tutorial_GPU",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x91VIMoTvwVu"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X06uoyTQweqR"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #CUAD를 사용하기 위한 device 설정\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqIgkSOTvwVu"
      },
      "source": [
        "#데이터 변환 입력 이미지를 torch.FloatTensor로 변환\n",
        "#N변환된 torch.FloatTensor를 Normalize한다 transforms.Normalize((mean),(std))\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), \n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4 #배치사이즈 hyperparameter 설정\n",
        "\n",
        "#training data set 설정 \n",
        "#root = str : data set의 루트 디렉토리 지정 인자\n",
        "#train = true : tarining set에서 data set 구성 인자\n",
        "#transform : 이미지 data를 변환하는 함수 설정 인자\n",
        "#download : data set 다운로드 설정 인자\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "#training data set loading 설정\n",
        "#trainset : load할 data set\n",
        "#batch_size : 로드할 배치당 셈플 수\n",
        "#shuffle : 각각의 epoch에서 data set를 다시 섞도록 설정\n",
        "#nun_workers : data load에 사용할 하위 프로세스 수\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "#test data set 설정\n",
        "#train = false : test set에서 data set 구성 인자\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "#test data set loading 설정\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "#클래스 10 설정\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfoslvZkvwVw"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() #부모클래스(nn.Moudle)의 내용을 사용하기 위해서 super()사용\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5) #2D convolution (input channel size, out channel size, kernel_size)\n",
        "        self.pool = nn.MaxPool2d(2, 2) #2D maxpooling (kernel_size, padding)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)  #2D convolution\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120) #Linear transformation (input_features, output_features)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x))) #conv1 relu pooling 계산 후 x 초기화\n",
        "        x = self.pool(F.relu(self.conv2(x))) #conv2 relu pooling 계산 후 x 초기화\n",
        "        x = torch.flatten(x, 1) #1차원 텐서로 변형\n",
        "        x = F.relu(self.fc1(x)) #fully connected 1 relu 후 x 초기화\n",
        "        x = F.relu(self.fc2(x)) #fully connected 2 relu 후 x 초기화\n",
        "        x = self.fc3(x) ##fully connected 3 계산 후 x 초기화\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net().to(device) #완성된 모델 초기화 + GPU로 올리기위한 인자"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzmmGhIHvwVx"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss() #crossentropyloss 사용\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) #optimizer로 SGD사용 (parameter 설정, learning rate, momentum 설정)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZJJ4hFDvwVx"
      },
      "source": [
        "for epoch in range(2): #트레이닝 셋이 신경망을 통과한 횟수 지정 \n",
        "\n",
        "    running_loss = 0.0 #loss 초기화\n",
        "    for i, data in enumerate(trainloader, 0): #반복문, training data 에서 traninloader를 통해 순서대로 data 불러오기\n",
        "        inputs, labels = data[0].to(device), data[1].to(device) #input data , label data 불러오기 + 설정된 device로 이동\n",
        "        optimizer.zero_grad() #torch.Tensor의 기울기를 0으로 초기화\n",
        "        outputs = net(inputs) #신경망 모델에 data 넣어 outpur 값 저장\n",
        "        loss = criterion(outputs, labels) #output값과 labels값을 통한 loss 값 crossentropyloss로 계산\n",
        "        loss.backward() #loss packprop\n",
        "        optimizer.step() #optimizer 매개변수 업데이트 \n",
        "        running_loss += loss.item() #loss값 저장\n",
        "        if i % 2000 == 1999:    \n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000)) #학습현황 표시\n",
        "            running_loss = 0.0 #loss 초기화\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDldvVyrvwVy"
      },
      "source": [
        "PATH = './cifar_net.pth' #학습한 parameter 값 저장 디렉토리 설정\n",
        "torch.save(net.state_dict(), PATH) # parameter 값 저장"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tmnsssavwVz"
      },
      "source": [
        "net = Net().to(device) #모델 불러오기\n",
        "net.load_state_dict(torch.load(PATH)) #학습한 parameter 불러오기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MCnJH8mvwV0"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad(): # 학습 중이 아니므로, 출력에 대한 변화도를 계산할 필요없음\n",
        "    for data in testloader: #test data set에서 testloader롤 통한 data 불러오기\n",
        "        images, labels = data[0].to(device), data[1].to(device) #불러온 data inages, labels 에 지정 및 설정된 device에 맞게 tensor 변환\n",
        "        outputs = net(images) # 신경망에 이미지를 통과시켜 출력을 계산\n",
        "        _, predicted = torch.max(outputs.data, 1) # 가장 높은 값(energy)를 갖는 분류(class)를 정답으로 선택\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXUahzy-vwV0"
      },
      "source": [
        "correct_pred = {classname: 0 for classname in classes} # 각 분류(class)에 대한 예측값 계산을 위한 설정\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "with torch.no_grad(): # 학습과정이 아니므로 변화도는 여전히 필요하지 않습니다\n",
        "    for data in testloader: #test data set에서 testloader롤 통한 data 불러오기\n",
        "        images, labels = data[0].to(device), data[1].to(device)  #불러온 data inages, labels 에 지정 및 설정된 device에 맞게 tensor 변환\n",
        "        outputs = net(images) # 신경망에 이미지를 통과시켜 출력을 계산\n",
        "        _, predictions = torch.max(outputs, 1) # 가장 높은 값(energy)를 갖는 분류(class)를 정답으로 선택\n",
        "        for label, prediction in zip(labels, predictions): # 각 분류별로 올바른 예측 수를 수집\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "for classname, correct_count in correct_pred.items(): # 각 분류별 정확도(accuracy)를 출력합니다\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname, accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}